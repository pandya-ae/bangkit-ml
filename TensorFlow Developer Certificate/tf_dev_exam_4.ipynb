{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf-dev-exam-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omsxOS64yKQ7",
        "outputId": "6d6260fa-f5c9-4629-f751-46b2d4d63e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 6s 7ms/step - loss: 0.6174 - accuracy: 0.6489 - val_loss: 0.5714 - val_accuracy: 0.7011\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5554 - accuracy: 0.7505 - val_loss: 0.5463 - val_accuracy: 0.7591\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5819 - accuracy: 0.7037 - val_loss: 0.6851 - val_accuracy: 0.5633\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6865 - accuracy: 0.5603 - val_loss: 0.6894 - val_accuracy: 0.5633\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6867 - accuracy: 0.5603 - val_loss: 0.6851 - val_accuracy: 0.5633\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6867 - accuracy: 0.5603 - val_loss: 0.6851 - val_accuracy: 0.5633\n",
            "Epoch 7/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6550 - accuracy: 0.6025 - val_loss: 0.5083 - val_accuracy: 0.7727\n",
            "Epoch 8/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4528 - accuracy: 0.7996 - val_loss: 0.4561 - val_accuracy: 0.7945\n",
            "Epoch 9/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4087 - accuracy: 0.8202 - val_loss: 0.4206 - val_accuracy: 0.8110\n",
            "Epoch 10/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3647 - accuracy: 0.8408 - val_loss: 0.4110 - val_accuracy: 0.8104\n",
            "Epoch 11/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3470 - accuracy: 0.8492 - val_loss: 0.4010 - val_accuracy: 0.8226\n",
            "Epoch 12/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3269 - accuracy: 0.8576 - val_loss: 0.4041 - val_accuracy: 0.8170\n",
            "Epoch 13/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3117 - accuracy: 0.8651 - val_loss: 0.3942 - val_accuracy: 0.8220\n",
            "Epoch 14/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2960 - accuracy: 0.8743 - val_loss: 0.4076 - val_accuracy: 0.8235\n",
            "Epoch 15/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2842 - accuracy: 0.8789 - val_loss: 0.4007 - val_accuracy: 0.8262\n",
            "Epoch 16/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2717 - accuracy: 0.8842 - val_loss: 0.4358 - val_accuracy: 0.8198\n",
            "Epoch 17/100\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2598 - accuracy: 0.8908 - val_loss: 0.4331 - val_accuracy: 0.8219\n",
            "Epoch 18/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2464 - accuracy: 0.8959 - val_loss: 0.4353 - val_accuracy: 0.8240\n",
            "Epoch 19/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2428 - accuracy: 0.8996 - val_loss: 0.4375 - val_accuracy: 0.8207\n",
            "Epoch 20/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2318 - accuracy: 0.9037 - val_loss: 0.4521 - val_accuracy: 0.8196\n",
            "Epoch 21/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2211 - accuracy: 0.9108 - val_loss: 0.4512 - val_accuracy: 0.8213\n",
            "Epoch 22/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2156 - accuracy: 0.9111 - val_loss: 0.4500 - val_accuracy: 0.8232\n",
            "Epoch 23/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2075 - accuracy: 0.9154 - val_loss: 0.4495 - val_accuracy: 0.8156\n",
            "Epoch 24/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2003 - accuracy: 0.9197 - val_loss: 0.4774 - val_accuracy: 0.8168\n",
            "Epoch 25/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1975 - accuracy: 0.9215 - val_loss: 0.4834 - val_accuracy: 0.8173\n",
            "Epoch 26/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1917 - accuracy: 0.9205 - val_loss: 0.4912 - val_accuracy: 0.8165\n",
            "Epoch 27/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2092 - accuracy: 0.9151 - val_loss: 0.4849 - val_accuracy: 0.8123\n",
            "Epoch 28/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1848 - accuracy: 0.9261 - val_loss: 0.5529 - val_accuracy: 0.8030\n",
            "Epoch 29/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1784 - accuracy: 0.9274 - val_loss: 0.5025 - val_accuracy: 0.8131\n",
            "Epoch 30/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1750 - accuracy: 0.9295 - val_loss: 0.4949 - val_accuracy: 0.8131\n",
            "Epoch 31/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1745 - accuracy: 0.9308 - val_loss: 0.4907 - val_accuracy: 0.8158\n",
            "Epoch 32/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1711 - accuracy: 0.9322 - val_loss: 0.5174 - val_accuracy: 0.8128\n",
            "Epoch 33/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1665 - accuracy: 0.9333 - val_loss: 0.5183 - val_accuracy: 0.8091\n",
            "Epoch 34/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1648 - accuracy: 0.9326 - val_loss: 0.5304 - val_accuracy: 0.8097\n",
            "Epoch 35/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1596 - accuracy: 0.9362 - val_loss: 0.5067 - val_accuracy: 0.8071\n",
            "Epoch 36/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1593 - accuracy: 0.9381 - val_loss: 0.5596 - val_accuracy: 0.8138\n",
            "Epoch 37/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1568 - accuracy: 0.9391 - val_loss: 0.5437 - val_accuracy: 0.8120\n",
            "Epoch 38/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1533 - accuracy: 0.9416 - val_loss: 0.5493 - val_accuracy: 0.8125\n",
            "Epoch 39/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1533 - accuracy: 0.9392 - val_loss: 0.5664 - val_accuracy: 0.8152\n",
            "Epoch 40/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1504 - accuracy: 0.9410 - val_loss: 0.5707 - val_accuracy: 0.8037\n",
            "Epoch 41/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1480 - accuracy: 0.9410 - val_loss: 0.5533 - val_accuracy: 0.8110\n",
            "Epoch 42/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1418 - accuracy: 0.9458 - val_loss: 0.5463 - val_accuracy: 0.8062\n",
            "Epoch 43/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1400 - accuracy: 0.9463 - val_loss: 0.5889 - val_accuracy: 0.8058\n",
            "Epoch 44/100\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1409 - accuracy: 0.9442 - val_loss: 0.5497 - val_accuracy: 0.8088\n",
            "Epoch 45/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1397 - accuracy: 0.9451 - val_loss: 0.5737 - val_accuracy: 0.8032\n",
            "Epoch 46/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1404 - accuracy: 0.9439 - val_loss: 0.5578 - val_accuracy: 0.8088\n",
            "Epoch 47/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1352 - accuracy: 0.9470 - val_loss: 0.5931 - val_accuracy: 0.8037\n",
            "Epoch 48/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1351 - accuracy: 0.9485 - val_loss: 0.5884 - val_accuracy: 0.8092\n",
            "Epoch 49/100\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1314 - accuracy: 0.9478 - val_loss: 0.6001 - val_accuracy: 0.8006\n",
            "Epoch 50/100\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.1298 - accuracy: 0.9505\n",
            "Desired accuracy is achieved.\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1296 - accuracy: 0.9505 - val_loss: 0.5959 - val_accuracy: 0.8100\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "# There are 5 questions in this exam with increasing difficulty from 1-5.\n",
        "# Please note that the weight of the grade for the question is relative\n",
        "# to its difficulty. So your Category 1 question will score significantly\n",
        "# less than your Category 5 question.\n",
        "#\n",
        "# Don't use lambda layers in your model.\n",
        "# You do not need them to solve the question.\n",
        "# Lambda layers are not supported by the grading infrastructure.\n",
        "#\n",
        "# You must use the Submit and Test button to submit your model\n",
        "# at least once in this category before you finally submit your exam,\n",
        "# otherwise you will score zero for this category.\n",
        "# ======================================================================\n",
        "#\n",
        "# NLP QUESTION\n",
        "#\n",
        "# Build and train a classifier for the sarcasm dataset.\n",
        "# The classifier should have a final layer with 1 neuron activated by sigmoid as shown.\n",
        "# It will be tested against a number of sentences that the network hasn't previously seen\n",
        "# and you will be scored on whether sarcasm was correctly detected in those sentences.\n",
        "\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if(logs.get('accuracy') > 0.95 and logs.get('val_accuracy') > 0.8):\n",
        "      print(\"\\nDesired accuracy is achieved.\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "def solution_model():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n",
        "    urllib.request.urlretrieve(url, 'sarcasm.json')\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n",
        "    vocab_size = 1000\n",
        "    embedding_dim = 16\n",
        "    max_length = 120\n",
        "    trunc_type='post'\n",
        "    padding_type='post'\n",
        "    oov_tok = \"<OOV>\"\n",
        "    training_size = 20000\n",
        "\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    # YOUR CODE HERE\n",
        "    with open(\"./sarcasm.json\", 'r') as f:\n",
        "      datastore = json.load(f)\n",
        "\n",
        "    for item in datastore:\n",
        "      sentences.append(item['headline'])\n",
        "      labels.append(item['is_sarcastic'])\n",
        "\n",
        "    training_sentences = sentences[0:training_size]\n",
        "    testing_sentences = sentences[training_size:]\n",
        "    training_labels = labels[0:training_size]\n",
        "    testing_labels = labels[training_size:]\n",
        "\n",
        "    tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
        "    tokenizer.fit_on_texts(training_sentences)\n",
        "    word_index = tokenizer.word_index\n",
        "\n",
        "    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "    training_padded = pad_sequences(training_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
        "    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
        "    testing_padded = pad_sequences(testing_sequences, maxlen = max_length, padding = padding_type, truncating = trunc_type)\n",
        "    \n",
        "    training_labels = np.array(training_labels)\n",
        "    testing_labels = np.array(testing_labels)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "    # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Conv1D(64, 5, activation = 'relu'),\n",
        "        tf.keras.layers.MaxPooling1D(pool_size = 4),\n",
        "        tf.keras.layers.LSTM(64),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    callback = myCallback()\n",
        "    \n",
        "    model.compile(\n",
        "        loss = 'binary_crossentropy',\n",
        "        optimizer = 'adam',\n",
        "        metrics = ['accuracy'])\n",
        "    \n",
        "    model.fit(\n",
        "        training_padded,\n",
        "        training_labels,\n",
        "        epochs = 100,\n",
        "        validation_data = (\n",
        "            testing_padded,\n",
        "            testing_labels),\n",
        "        callbacks = callback)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")"
      ]
    }
  ]
}